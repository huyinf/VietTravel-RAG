some approaches for crawling web

- Command-Line Search Tools (DuckDuckGo CLI)
- Custom Python Script (Web Scraping) + Elasticsearch (indexing - furture work)
- SearXNG Meta-Search (Self-Hosted with docker)
- Search Engine APIs (Google, Bing, DuckDuckGo)

# plan

- try all to choose the best quality 

> ddg cli to get links + web scaping to get content

# plan of preparing data

- urls --> raw content --> format content --> save to json

# choose models for processing text

- choose models (free-only) with criteria
    - context
    - latency

- record all results