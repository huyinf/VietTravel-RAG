{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.schema import Document\n",
    "import torch\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer, LlamaConfig\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import PyPDF2\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- LLM Model Loading ---\n",
    "torch_dtype = torch.bfloat16\n",
    "model_id = \"llm4fun/vietrag-7b-v1.0\"\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    config=LlamaConfig.from_pretrained(model_id),\n",
    "    torch_dtype=torch_dtype\n",
    ")\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='ĐẠI HỌC QUỐC GIA THÀNH PHỐ HỒ CHÍ MINH\\nTRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN\\nKHOA CÔNG NGHỆ THÔNG TIN\\nTRÍ TUỆ NHÂN TẠO CHO AN NINH THÔNG TIN\\nBÁO CÁO BÀI TẬP THỰC HÀNH\\nLab 4 - Bảo mật trong Quá trình Huấn luyện\\nMô hình Máy học\\nThành viên:\\n21120157 - Lê Phạm Hoàng Trung\\n21120415 - Trần Ngọc Bảo\\nKhoa: Công nghệ Thông tin\\nThành phố Hồ Chí Minh - 2024'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nMục lục\\nI Thông tin chung 4\\nII Nội dung báo cáo 5\\n1 Mô hình gốc ban đầu 5\\n1.1 Tổng quan về Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.2 Cấu trúc mô hình sử dụng ResNet-18 trong FL . . . . . . . . . . . . . . . . . . . . . . 5\\n1.3 Quy trình hoạt động của máy chủ (Server) . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.4 Quy trình hoạt động của máy khách (Client) . . . . . . . . . . . . . . . . . . . . . . . 6\\n1.5 Tổng hợp mô hình . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nIII Nội dung báo cáo 7\\n2 Xây dựng mô hình tấn công 7\\n2.1 Các bước triển khai PGD Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n2.2 Tích hợp vào client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3 Xây dựng mô hình phòng thủ tại Server 8\\n3.1 Tại sao lựa chọn Adversarial Training? . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.2 Mô hình phòng thủ: Adversarial Defense Training . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 Tích hợp vào server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n4 Quan sát kết quả 10\\n4.1 Mô hình trước khi phòng thủ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n4.2 Mô hình sau khi phòng thủ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n4.3 Nhận xét . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\nAI4Sec Trang: 1 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nDanh sách hình vẽ\\n1 Độ chính xác của mô hình toàn cục sử dụng Resnet18 trước khi áp dụng tấn công . . . 10\\n2Độ chính xác của mô hình toàn cục sử dụng Resnet18 sau khi áp dụng tấn công và phòng\\nthủ tại Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\nAI4Sec Trang: 2 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nDanh sách bảng\\n1 Bảng tự đánh giá mức độ hoàn thành công việc . . . . . . . . . . . . . . . . . . . . . 4\\n2 Bảng phân chia công việc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nAI4Sec Trang: 3 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nPhần I\\nThông tin chung\\nBảng tự đánh giá và bảng phân công công việc.\\nNội dung Mức độ hoàn thành\\nXây dựng mô hình tấn công 100%\\nTinh chỉnh lại mô hình để đạt hiệu suất cao hơn 70% 100%\\nXây dựng mô hình phòng thủ tại Server 100%\\nViết báo cáo 100%\\nBảng 1: Bảng tự đánh giá mức độ hoàn thành công việc\\nThành viên MSSV Các công việc thực hiện Mức độ\\nLê Phạm Hoàng Trung 21120157 Xây dựng mô hình phòng thủ 100%\\nTrần Ngọc Bảo 21120415 Xây dựng mô hình tấn công 100%\\nBảng 2: Bảng phân chia công việc\\nAI4Sec Trang: 4 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nPhần II\\nNội dung báo cáo\\n1 Mô hình gốc ban đầu\\n1.1 Tổng quan về Federated Learning\\nFederated Learning (FL) là một phương pháp học máy phân tán, nơi nhiều thiết bị hoặc nút tính toán\\ncục bộ tham gia vào việc huấn luyện một mô hình chung mà không cần chia sẻ dữ liệu thô. Thay vào đó,\\ncác thiết bị này cập nhật mô hình cục bộ và gửi các tham số (weights) hoặc gradients đã học được về\\ncho máy chủ trung tâm. Máy chủ thực hiện việc tổng hợp các tham số này để tạo ra một mô hình toàn\\ncục được cải tiến, sau đó gửi mô hình cập nhật lại cho các thiết bị để tiếp tục huấn luyện. Phương pháp\\nnày giúp bảo vệ quyền riêng tư dữ liệu, giảm tải băng thông và cải thiện khả năng mở rộng hệ thống.\\n1.2 Cấu trúc mô hình sử dụng ResNet-18 trong FL\\nTrong bài toán này, chúng em sử dụng một biến thể của ResNet-18, một kiến trúc mạng nơ-ron tích\\nchập (CNN) mạnh mẽ, làm trình trích xuất đặc trưng. ResNet-18 có khả năng học được các biểu diễn\\nmạnh mẽ từ dữ liệu hình ảnh, nhờ vào các khối residual kết hợp. Sau tầng trích xuất đặc trưng, một lớp\\nhồi quy logistic được gắn kèm để thực hiện phân loại đầu ra với 10 lớp của tập dữ liệu CIFAR-10. Điều\\nnày tạo nên mô hình LogisticRegressionModelV2, nơi ResNet-18 đóng vai trò nền tảng, kết hợp với lớp\\nlogistic để hoàn thiện quy trình huấn luyện.\\n1.3 Quy trình hoạt động của máy chủ (Server)\\nServer đóng vai trò trung tâm trong việc tổng hợp mô hình và điều phối giao tiếp với các client. Quy\\ntrình hoạt động của server có thể được mô tả qua các bước sau:\\n•Khởi tạo: Server bắt đầu bằng việc tạo một mô hình toàn cục (global model) ở trạng thái khởi\\nđầu và tải dữ liệu kiểm thử (test dataset) để đánh giá hiệu năng của mô hình.\\n•Nhận dữ liệu từ client: Server lắng nghe và nhận các tham số mô hình đã được huấn luyện cục bộ\\ntừ mỗi client. Các tham số này được lưu lại để chuẩn bị cho việc tổng hợp.\\n•Tổng hợp mô hình: Server thực hiện việc tổng hợp mô hình bằng cách tính trung bình các tham số\\ntừ tất cả client. Việc này đảm bảo rằng kiến thức từ các client được hợp nhất mà không cần chia\\nsẻ dữ liệu.\\nAI4Sec Trang: 5 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\n•Đánh giá hiệu năng: Sau khi tổng hợp, server đánh giá mô hình toàn cục với dữ liệu thông thường\\n(normal accuracy) và dữ liệu tấn công đối kháng (adversarial accuracy). Điều này giúp kiểm tra\\nkhả năng chống chịu của mô hình trước các tấn công đối kháng.\\n•Gửi lại mô hình: Server gửi mô hình toàn cục được cập nhật lại cho các client để tiếp tục quá\\ntrình huấn luyện.\\n•Lưu trữ mô hình tốt nhất: Nếu mô hình toàn cục mới đạt được độ chính xác cao hơn các phiên\\nbản trước, server lưu trữ mô hình này làm phiên bản tối ưu.\\n1.4 Quy trình hoạt động của máy khách (Client)\\nClient thực hiện việc huấn luyện mô hình cục bộ và giao tiếp với server để cập nhật mô hình toàn\\ncục. Các bước chính trong quy trình của client bao gồm:\\n•Nhận mô hình toàn cục: Client nhận mô hình được cập nhật từ server ở mỗi vòng lặp và sử dụng\\nmô hình này làm trạng thái khởi đầu cho việc huấn luyện cục bộ.\\n•Huấn luyện cục bộ: Client sử dụng tập dữ liệu cục bộ riêng biệt và tiến hành huấn luyện mô hình\\ntrong nhiều epoch. Việc này đảm bảo mô hình học được đặc trưng từ dữ liệu riêng mà không cần\\nchia sẻ dữ liệu với server.\\n•Gửi lại mô hình: Sau khi hoàn thành huấn luyện, client gửi tham số của mô hình cục bộ đã được\\ncập nhật về server để tham gia vào quá trình tổng hợp.\\n•Cập nhật mô hình: Sau mỗi vòng lặp, client nhận mô hình mới từ server và cập nhật trạng thái\\nmô hình cục bộ để tiếp tục vòng huấn luyện tiếp theo.\\n1.5 Tổng hợp mô hình\\nQuá trình tổng hợp mô hình toàn cục tại máy chủ được thực hiện thông qua lấy trung bình các tham\\nsố (parameter averaging). Điều này giúp hợp nhất kiến thức từ nhiều nguồn dữ liệu khác nhau mà vẫn\\nđảm bảo tính bảo mật dữ liệu. Đồng thời, trong kịch bản bảo vệ tính bền vững, mô hình được đánh giá\\ntrên các mẫu đối kháng (adversarial examples) được tạo bằng phương pháp PGD (Projected Gradient\\nDescent). Phương pháp PGD liên tục điều chỉnh dữ liệu để tìm kiếm các mẫu có thể đánh lừa mô hình,\\nqua đó đo lường khả năng chống chịu của mô hình trước các tấn công.\\nAI4Sec Trang: 6 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nPhần III\\nNội dung báo cáo\\n2 Xây dựng mô hình tấn công\\nAdversarial attack là một loại tấn công đặc biệt vào mô hình học sâu, trong đó các mẫu đầu vào được\\nthêm nhiễu nhỏ (không ảnh hưởng đến nhận thức của con người) nhưng đủ để gây ra lỗi nghiêm trọng\\ncho mô hình. Các tấn công như Projected Gradient Descent (PGD) hoặc Fast Gradient Sign Method\\n(FGSM) đã được chứng minh là cực kỳ hiệu quả trong việc làm suy giảm hiệu suất của các mô hình\\ndeep learning, ngay cả các mô hình đạt kết quả tốt trên dữ liệu gốc. Ở phần này, nhóm chúng em sẽ\\ntriển khai mô hình PGD Attack cho nhiệm vụ xây dựng mô hình tấn công.\\n2.1 Các bước triển khai PGD Attack\\n•Tính toán gradient ngược trên dữ liệu gốc:\\n* Input ban đầu (images) được chuyển thành một tensor yêu cầu gradient\\n1 images . requires_grad = True\\n2\\n* Mô hình dự đoán đầu ra và tính toán hàm mất mát dựa trên dự đoán\\n1 loss = F. cross_entropy ( outputs , labels )\\n2\\n* Thực hiện lan truyền ngược để tính gradient của các input\\n•Cập nhật dữ liệu đối kháng: Gradient của loss đối với input được sử dụng để điều chỉnh giá trị\\ncủa dữ liệu đầu vào theo hướng tăng khả năng dự đoán sai\\n1 adv_images = images + alpha * images . grad . sign ()\\n2\\n•Dựng lại mẫu đối kháng: Mẫu mới được giới hạn trong một khoảng epsilon để đảm bảo nó vẫn\\ngần với dữ liệu gốc\\n1 eta = torch . clamp ( adv_images - original_images , min=- epsilon , max=\\nepsilon )\\n2 images = torch . clamp ( original_images + eta , min =0, max =1). detach ()\\n3\\nAI4Sec Trang: 7 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\n2.2 Tích hợp vào client\\nTrong file client.py , PGD Attack được sử dụng khi huấn luyện mô hình cục bộ, bằng cách:\\n•Tạo ra các mẫu đối kháng (adv_inputs) từ dữ liệu gốc.\\n•Kết hợp dữ liệu gốc và dữ liệu đối kháng để tạo tập huấn luyện mở rộng:\\n1 mixed_inputs = torch . cat ([ inputs , adv_inputs ], dim =0)\\n2 mixed_targets = torch .cat ([ targets , targets ], dim =0)\\n3\\n•Mô hình được huấn luyện trên tập dữ liệu này để cải thiện khả năng chịu đựng trước các tấn công.\\n3 Xây dựng mô hình phòng thủ tại Server\\nAdversarial defense là một nhánh quan trọng trong nghiên cứu bảo mật AI nhằm cải thiện khả năng\\nchống chịu của các mô hình đối với các cuộc tấn công dạng này. Một trong các chiến lược phòng thủ\\nmạnh nhất hiện nay là Adversarial Training, được đề xuất bởi Ian Goodfellow và cộng sự trong bài báo\\n\"Explaining and Harnessing Adversarial Examples\" [2].\\n3.1 Tại sao lựa chọn Adversarial Training?\\nAdversarial Training là kỹ thuật huấn luyện mô hình không chỉ với các mẫu dữ liệu gốc mà còn với các\\nmẫu đối kháng được tạo ra trong thời gian thực. Kỹ thuật này giúp mô hình \"học\" cách nhận diện và\\nphân loại chính xác ngay cả khi đầu vào bị nhiễu. Dưới đây là các lý do chính giải thích tại sao phương\\npháp này hiệu quả:\\n•Trong Adversarial Training, mô hình được tiếp xúc với các mẫu tấn công ngay từ khi huấn luyện,\\ngiúp nó \"quen thuộc\" với các loại nhiễu thường gặp trong thực tế. Điều này khác với các phương\\npháp chỉ huấn luyện trên dữ liệu gốc và sau đó sử dụng phòng thủ ở giai đoạn suy luận.\\n•Mặc dù các mẫu đối kháng thường được tạo ra để tấn công một mô hình cụ thể, Adversarial\\nTraining có thể giúp cải thiện khả năng tổng quát hóa trên cả dữ liệu gốc và các dạng dữ liệu bị\\nnhiễu khác nhau. Điều này đặc biệt quan trọng trong các hệ thống học máy áp dụng thực tế, nơi\\nmô hình phải đối mặt với nhiều kiểu biến dạng dữ liệu.\\n•Các phương pháp phòng thủ như Gradient Masking hoặc Input Preprocessing thường không bền\\nvững trước các kiểu tấn công nâng cao. Adversarial Training, trái lại, trực tiếp giải quyết vấn đề\\nbằng cách tối ưu hóa mô hình để đối phó với nhiễu ngay trong quá trình học, giúp nó bền vững\\nhơn [1]\\nAI4Sec Trang: 8 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\n3.2 Mô hình phòng thủ: Adversarial Defense Training\\n•Kết hợp mẫu gốc và mẫu đối kháng:\\n* Server thực hiện huấn luyện thêm trên mô hình tổng hợp từ các client\\n*Tương tự như phía client, server tạo mẫu đối kháng bằng PGD Attack và kết hợp với dữ liệu\\ngốc\\n1 mixed_inputs = torch . cat ([ inputs , adv_inputs ], dim =0)\\n2 mixed_targets = torch .cat ([ targets , targets ], dim =0)\\n3\\n•Huấn luyện lại mô hình với mẫu hỗn hợp:\\n*Sử dụng tập dữ liệu thử nghiệm (test_loader) từ CIFAR-10, server thực hiện quá trình huấn\\nluyện lại mô hình với mẫu đối kháng.\\n*Quá trình huấn luyện diễn ra qua nhiều epoch để đảm bảo mô hình cải thiện khả năng chống\\nchịu tấn công.\\n•Phân tích độ chính xác: Độ chính xác được đánh giá trên cả tập dữ liệu gốc (Normal Accuracy)\\nvà Độ chính xác đối kháng (Adversarial Accuracy) khi mô hình bị tấn công với các mẫu đối kháng.\\n3.3 Tích hợp vào server\\nMô hình phòng thủ được triển khai trong server.py, với quá trình huấn luyện được gọi sau khi mô\\nhình toàn cầu (global model) được tổng hợp từ các client:\\n1adversarial_defense_training (model , test_loader , criterion , optimizer , device =\\ndevice , epsilon =0.03 , alpha =0.005 , num_iter =10 , epochs =5)\\nAI4Sec Trang: 9 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\n4 Quan sát kết quả\\n4.1 Mô hình trước khi phòng thủ\\nĐối với mô hình truyền thống, qua 10vòng học, mô hình toàn cục với đặc trưng được trích xuất\\nbằng Resnet18 có được độ chính xác trên tập test là 80.9%và cũng là mô hình có độ chính xác tốt nhất\\ntrong 10mô hình của mỗi vòng (Hình 1).1\\nHình 1: Độ chính xác của mô hình toàn cục sử dụng Resnet18 trước khi áp dụng tấn công\\n4.2 Mô hình sau khi phòng thủ\\nĐối với mô hình sau khi đã áp dụng phương pháp tấn công và phòng thủ, qua 10vòng học, mô hình\\ntoàn cục với đặc trưng được trích xuất bằng Resnet18 có được độ chính xác trên tập test là 45.96%và\\ncũng là mô hình có độ chính xác tốt nhất trong 10mô hình của mỗi vòng (Hình 2).\\n4.3 Nhận xét\\nSự sụt giảm đáng kể về độ chính xác từ 80.90%xuống 44%sau khi áp dụng phương pháp phòng thủ,\\nchẳng hạn như Adversarial Training, là một hiện tượng phổ biến trong học máy đối kháng và có thể\\nđược giải thích qua nhiều khía cạnh như sau:\\n1Số liệu được lấy từ bài báo cáo ở lab 2.\\nAI4Sec Trang: 10 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nHình 2: Độ chính xác của mô hình toàn cục sử dụng Resnet18 sau khi áp dụng tấn công và phòng thủ\\ntại Server\\n•Đầu tiên, là do mô hình đã có sự đánh đổi giữa tính tổng quát trên dữ liệu sạch và tính kháng cự\\ntrên dữ liệu đối kháng:\\n* Mô hình ban đầu (trước khi phòng thủ):\\n∗Được huấn luyện trên dữ liệu gốc (sạch), tối ưu hóa hoàn toàn để đạt hiệu suất tốt trên\\ndữ liệu này.\\n∗Vì không phải tối ưu thêm cho khả năng kháng cự với tấn công đối kháng, mô hình vẫn\\ngiữ được độ chính xác cao trên dữ liệu sạch.\\n* Mô hình sau phòng thủ:\\n∗Quá trình Adversarial Training đưa thêm dữ liệu đối kháng (adversarial examples) vào\\nquá trình huấn luyện. Khi đó, mô hình phải học cách phân biệt cả dữ liệu sạch lẫn dữ\\nliệu đối kháng.\\n∗Điều này tạo ra một sự đánh đổi (trade-off) vì mô hình cần tối ưu thêm cho khả năng\\nchống chịu với các tấn công thay vì chỉ tập trung vào độ chính xác trên dữ liệu sạch.\\n∗Kết quả là mô hình sau phòng thủ có thể mất đi một phần hiệu suất trên dữ liệu gốc.\\n•Sự phân bổ tài nguyên huấn luyện của mô hình: Mô hình phải phân bổ tài nguyên (parameters,\\ngradients) để học cách kháng cự với dữ liệu đối kháng. Vì không có tài nguyên dư thừa, điều này\\ncó thể dẫn đến việc mô hình không còn đủ khả năng để tối ưu hóa trên dữ liệu gốc.\\n•Phụ thuộc vào các siêu tham số trong quá trình huấn luyện phòng thủ:\\nAI4Sec Trang: 11 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\n*Epsilon (mức độ nhiễu): Nếu giá trị epsilon quá lớn, các mẫu đối kháng được tạo ra có thể\\nrất khác biệt so với dữ liệu sạch, dẫn đến khó khăn trong việc cân bằng giữa dữ liệu gốc và\\nđối kháng.\\n*Alpha và số lần lặp của PGD: Nếu quá trình tạo mẫu đối kháng quá mạnh, mô hình sẽ bị\\n\"quá tải\" khi phải xử lý chúng, dẫn đến mất hiệu suất trên dữ liệu gốc.\\nAI4Sec Trang: 12 / 13'),\n",
       " Document(metadata={}, page_content='Trường Đại học Khoa học Tự Nhiên TP.HCM Khoa: Công nghệ Thông tin\\nTài liệu\\n[1]Nicholas Carlini and David Wagner. Adversarial Examples Are Not Easily Detected: Bypassing Ten\\nDetection Methods . 2017. arXiv: 1705.07263 [cs.LG] .url:https://arxiv.org/abs/1705.\\n07263.\\n[2]Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and Harnessing Adversarial\\nExamples . 2015. arXiv: 1412.6572 [stat.ML] .url:https://arxiv.org/abs/1412.6572 .\\nAI4Sec Trang: 13 / 13')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract text from a PDF file using PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    corpus = []\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:  # Ensure there's text on the page\n",
    "                corpus.append(text.strip())\n",
    "    return corpus\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = \"/home/jupyter-trunglph/Others/RAG/21120157_21120415.pdf\"\n",
    "\n",
    "# Extract the corpus from the PDF\n",
    "raw_texts = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Convert extracted text to Document objects\n",
    "docs = [Document(page_content=text) for text in raw_texts]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Wrap the embedding model\n",
    "def embed_documents(texts):\n",
    "    return embedding_model.encode(texts, convert_to_tensor=True).cpu().numpy()\n",
    "  \n",
    "# Initialize a FAISS index\n",
    "dimension = embedding_model.get_sentence_embedding_dimension()\n",
    "index = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3ed7e692-2756-4fcc-99a4-50d5917e702a',\n",
       " '997d6f70-e213-4a10-b482-19b995c00d98',\n",
       " '2fa0eef2-930f-4912-88f1-057e9f06e8db',\n",
       " '9f1df2a4-33a4-4aa3-b651-3ce71fa2f25a',\n",
       " '8777799d-fbcf-4d2b-bb20-b926bcd5a9c9',\n",
       " '734b3439-24fc-47bd-8343-0079347d5703',\n",
       " '0e6a9067-bb44-473f-afa5-45ddc5889086',\n",
       " '458ce342-0610-4b11-8cd5-8e6da7c9a28f',\n",
       " '0e501bdb-b5a4-48e2-9c45-11950320fbd0',\n",
       " '5f59a1a0-6302-447e-8ceb-293f7c0d79cf',\n",
       " '8717cfa7-8753-4a1f-bf1c-16bf24d35b4d',\n",
       " '503ec3fd-78a3-46bd-b5c0-232fc779085a',\n",
       " '20eb483c-3340-49e9-9d0a-83e20c6b3a72',\n",
       " 'b143a4f2-ae99-4382-86b7-980c2006b876',\n",
       " '81e25ed1-24b8-43d1-b1ae-d9cae74e9f94',\n",
       " 'e80e8904-3ba4-424e-a832-33dc4a236d83',\n",
       " '4f9d2448-29ed-48e1-8ee3-ab536f0043cb',\n",
       " 'f93c4343-756f-416d-8282-ab9e44e8dc04',\n",
       " 'b61fd387-0e1c-4be0-ae97-b3c9617a8460',\n",
       " '236d367c-0477-4b56-a279-7f4e6004430f',\n",
       " '6141209c-295d-4cd2-8814-a2fb476e63b7',\n",
       " '5e0bfb63-d083-4edf-ab8d-475a5db1bb14',\n",
       " 'c2863f64-2d7a-42fb-b5ba-f59435854e74',\n",
       " '1f1d8844-cfc5-47c9-8bb9-a5f60465afb2',\n",
       " '2a3e2ef5-13a1-4a32-bcfc-83b1e502dc01']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = FAISS(\n",
    "    embedding_function=embed_documents,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prompt Construction ---\n",
    "prompt_template = (\n",
    "  \"### System:\\n\"\n",
    "  \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "  \"Write a response that appropriately completes the request.\\n\\n\\n\\n\"\n",
    "  \"### Instruction:\\n{instruction}\\n\\n\"\n",
    "  \"### Input:\\n{input}\\n\\n\"\n",
    "  \"### Response:\\n{output}\"\n",
    ")\n",
    "\n",
    "def get_prompt(question, contexts):\n",
    "  \"\"\"Generate a prompt for the language model.\"\"\"\n",
    "  context = \"\\n\\n\".join([f\"Context [{i+1}]: {x.page_content}\" for i, x in enumerate(contexts)])\n",
    "  instruction = 'You are an AI assistant. Provide a detailed answer so user don’t need to search outside to understand the answer.'\n",
    "  input = f\"Dựa vào một số ngữ cảnh được cho dưới đây, trả lời câu hỏi ở cuối.\\n\\n{context}\\n\\nQuestion: {question}\\nHãy trả lời chi tiết và đầy đủ.\"\n",
    "  prompt = prompt_template.format(\n",
    "      instruction=instruction,\n",
    "      input=input,\n",
    "      output=''\n",
    "  )\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Vector Search with FAISS ---\n",
    "def retrieve(question, topk=3):\n",
    "  \"\"\"\n",
    "  Retrieve the most relevant passages using FAISS and vector similarity.\n",
    "  \"\"\"\n",
    "\n",
    "  results = vector_store.similarity_search(question, k=topk)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens=1024):\n",
    "  \"\"\"\n",
    "  Generate a text response from the language model using the provided prompt.\n",
    "  \"\"\"\n",
    "  input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(model.device)\n",
    "  \n",
    "  # Perform text generation\n",
    "  with torch.no_grad():\n",
    "      generation_config = GenerationConfig(\n",
    "          repetition_penalty=1.13,\n",
    "          max_new_tokens=max_new_tokens,\n",
    "          pad_token_id=tokenizer.pad_token_id,\n",
    "          do_sample=False,\n",
    "          use_cache=True,\n",
    "      )\n",
    "      generated = model.generate(\n",
    "          inputs=input_ids,\n",
    "          generation_config=generation_config,\n",
    "      )\n",
    "  \n",
    "  # Get the generated tokens, starting from where the input ends\n",
    "  gen_tokens = generated.cpu()[:, input_ids.shape[-1]:]  # Slice from the input length onward\n",
    "  output = tokenizer.batch_decode(gen_tokens)[0]\n",
    "  return output.replace(\"</s>\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAG Pipeline ---\n",
    "def rag_pipeline(question, topk=3):\n",
    "  \"\"\"\n",
    "  End-to-end pipeline for retrieval-augmented generation (RAG).\n",
    "  \"\"\"\n",
    "  # Retrieve relevant contexts\n",
    "  top_passages = retrieve(question, topk=topk)\n",
    "  # Generate a prompt\n",
    "  prompt = get_prompt(question, top_passages)\n",
    "  # Generate answer using the LLM\n",
    "  generated_answer = generate(prompt)\n",
    "  result = {\n",
    "      \"retrieved_context\": top_passages,\n",
    "      \"generated_answer\": generated_answer\n",
    "  }\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question: Federated Learning là gì?\n",
      "Generated Answer:\n",
      "Federated Learning (FL) là một phương pháp học máy phân tán, nơi nhiều thiết bị hoặc nút tính toán cục bộ tham gia vào việc huấn luyện một mô hình chung mà không cần chia sẻ dữ liệu thô [1]. Nó giúp bảo vệ quyền riêng tư dữ liệu, giảm tải băng thông và cải thiện khả năng mở rộng hệ thống [1] [5]. Trong bài toán này, một biến thể của ResNet-18, một kiến trúc mạng nơ-ron tích chập (CNN) mạnh mẽ, được sử dụng làm trình trích xuất đặc trưng [1]. Mô hình gốc được tạo ra bằng cách huấn luyện mô hình cục bộ và gửi các tham số (weights) hoặc gradients đã học được về cho máy chủ trung tâm [1]. Sau đó, mô hình cập nhật lại được gửi lại cho các thiết bị để tiếp tục huấn luyện [1].\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question: Resnet18 là gì?\n",
      "Generated Answer:\n",
      "ResNet-18 là một kiến trúc mạng nơ-ron tích chập (CNN) mạnh mẽ, làm trình trích xuất đặc trưng và được sử dụng làm nền tảng cho mô hình LogisticRegressionModelV2 trong bài toán được đề cập. Nó được sử dụng để trích xuất các đặc trưng từ dữ liệu hình ảnh và sau đó được gắn kèm với một lớp hồi quy logistic để thực hiện phân loại đầu ra với 10 lớp của tập dữ liệu CIFAR-10 [1]. Mô hình này được tạo ra bằng cách tạo một mô hình toàn cục (global model) ở trạng thái khởi đầu và tải dữ liệu kiểm tra (test dataset) để đánh giá hiệu suất của mô hình [1] [2].\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question: Adversarial Training là gì?\n",
      "Generated Answer:\n",
      "Adversarial Training là một kỹ thuật huấn luyện mô hình học máy đối kháng, giúp mô hình \"học\" cách nhận diện và phân loại chính xác ngay cả khi đầu vào bị nhiễu. Nó hoạt động bằng cách tiếp xúc mô hình với các mẫu tấn công ngay từ khi huấn luyện, giúp nó \"quen thuộc\" với các loại nhiễu thường gặp trong thực tế [5]. Phương pháp này được đề xuất bởi Ian Goodfellow và cộng sự trong bài báo “Explaining and Harnessing Adversarial Examples” [2], và mạnh nhất hiện nay là Adversarial Training [5].\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question:  Tại sao lựa chọn Adversarial Training?\n",
      "Generated Answer:\n",
      "Lựa chọn Adversarial Training là một kỹ thuật hiệu quả để huấn luyện mô hình không chỉ với các mẫu dữ liệu gốc mà còn với các mẫu đối kháng được tạo ra trong thời gian thực [4]. Điều này giúp mô hình “học” cách nhận diện và phân loại chính xác ngay cả khi đầu vào bị nhiễu [4], đồng thời mang lại khả năng tổng quát cao hơn trên cả dữ liệu gốc và các dạng dữ liệu bị nhiễu [4]. Hơn nữa, Adversarial Training có thể giúp cải thiện Độ chính xác đối kháng (Adversarial Accuracy) khi mô hình bị tấn công với các mẫu đối kháng [4] [5].\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Federated Learning là gì?\",\n",
    "    \"Resnet18 là gì?\",\n",
    "    \"Adversarial Training là gì?\",\n",
    "    \" Tại sao lựa chọn Adversarial Training?\"\n",
    "]\n",
    "\n",
    "# Step 4: Answer each question using RAG\n",
    "for question in questions:\n",
    "  print(f\"\\n\\n{'='*50}\")\n",
    "  print(f\"\\nQuestion: {question}\")\n",
    "  result = rag_pipeline(question, topk=5)\n",
    "\n",
    "  print(\"Generated Answer:\")\n",
    "  print(result[\"generated_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
